{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba53c8cf",
   "metadata": {},
   "source": [
    "# RST Trap Finder - Basic Usage Tutorial\n",
    "\n",
    "This notebook demonstrates the basic functionality of the RST Trap Finder toolkit for analyzing word association graphs to identify trap words.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and load our sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from rst_trap_finder import TRAP_LETTERS\n",
    "from rst_trap_finder.io import load_csv\n",
    "from rst_trap_finder.scores import (\n",
    "    one_step_rst_prob, escape_hardness, biased_pagerank,\n",
    "    k_step_rst_prob, minimax_topm, composite\n",
    ")\n",
    "from rst_trap_finder.strategy import recommend_next\n",
    "from rst_trap_finder.data_processing import DataProcessor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Trap letters: {TRAP_LETTERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8ee4c",
   "metadata": {},
   "source": [
    "## Loading and Exploring Data\n",
    "\n",
    "Let's load the sample word association graph and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample graph\n",
    "graph = load_csv('../data/edges.sample.csv')\n",
    "\n",
    "print(f\"Graph loaded with {len(graph)} nodes\")\n",
    "print(\"\\nFirst 5 nodes and their connections:\")\n",
    "for i, (node, connections) in enumerate(graph.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"{node}: {dict(connections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d01c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive data summary\n",
    "summary = DataProcessor.get_data_summary(graph)\n",
    "\n",
    "print(\"Graph Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2efe6",
   "metadata": {},
   "source": [
    "## Basic Scoring Functions\n",
    "\n",
    "Let's compute the basic trap scores for all words in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb876e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PageRank with bias toward trap letters\n",
    "pagerank = biased_pagerank(graph, TRAP_LETTERS, alpha=1.5)\n",
    "\n",
    "# Compute scores for all nodes\n",
    "results = []\n",
    "\n",
    "for word in graph:\n",
    "    scores = {\n",
    "        'word': word,\n",
    "        'one_step': one_step_rst_prob(word, graph, TRAP_LETTERS),\n",
    "        'escape_hardness': escape_hardness(word, graph, TRAP_LETTERS),\n",
    "        'pagerank': pagerank.get(word, 0.0),\n",
    "        'k2_step': k_step_rst_prob(word, graph, TRAP_LETTERS, k=2),\n",
    "        'minimax': minimax_topm(word, graph, TRAP_LETTERS),\n",
    "        'is_trap': word and word[0] in TRAP_LETTERS\n",
    "    }\n",
    "    \n",
    "    # Compute composite score\n",
    "    scores['composite'] = composite(word, graph, TRAP_LETTERS, pagerank)\n",
    "    \n",
    "    results.append(scores)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"Computed scores for {len(df)} words\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5447b",
   "metadata": {},
   "source": [
    "## Top Trap Words\n",
    "\n",
    "Let's find and analyze the most effective trap words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by composite score and show top 10\n",
    "top_words = df.nlargest(10, 'composite')\n",
    "\n",
    "print(\"Top 10 Trap Words by Composite Score:\")\n",
    "print(top_words[['word', 'composite', 'one_step', 'escape_hardness', 'is_trap']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f49503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare trap vs non-trap words\n",
    "trap_words = df[df['is_trap']]\n",
    "non_trap_words = df[~df['is_trap']]\n",
    "\n",
    "print(\"Score Comparison:\")\n",
    "print(f\"Trap words (n={len(trap_words)}):\")\n",
    "print(f\"  Mean composite score: {trap_words['composite'].mean():.3f}\")\n",
    "print(f\"  Mean one-step prob: {trap_words['one_step'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nNon-trap words (n={len(non_trap_words)}):\")\n",
    "print(f\"  Mean composite score: {non_trap_words['composite'].mean():.3f}\")\n",
    "print(f\"  Mean one-step prob: {non_trap_words['one_step'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e8fa14",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's create some visualizations to better understand the score distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ddc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score distribution plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Composite score distribution\n",
    "axes[0, 0].hist(df['composite'], bins=20, alpha=0.7, color='blue')\n",
    "axes[0, 0].set_title('Composite Score Distribution')\n",
    "axes[0, 0].set_xlabel('Composite Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# One-step probability distribution by trap status\n",
    "axes[0, 1].hist(trap_words['one_step'], bins=15, alpha=0.7, color='red', label='Trap words')\n",
    "axes[0, 1].hist(non_trap_words['one_step'], bins=15, alpha=0.7, color='blue', label='Non-trap words')\n",
    "axes[0, 1].set_title('One-Step RST Probability')\n",
    "axes[0, 1].set_xlabel('One-Step Probability')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Scatter plot: One-step vs Composite\n",
    "axes[1, 0].scatter(df['one_step'], df['composite'], \n",
    "                   c=['red' if trap else 'blue' for trap in df['is_trap']], alpha=0.6)\n",
    "axes[1, 0].set_title('One-Step vs Composite Score')\n",
    "axes[1, 0].set_xlabel('One-Step Probability')\n",
    "axes[1, 0].set_ylabel('Composite Score')\n",
    "\n",
    "# Top words bar chart\n",
    "top_10 = df.nlargest(10, 'composite')\n",
    "colors = ['red' if trap else 'blue' for trap in top_10['is_trap']]\n",
    "axes[1, 1].bar(range(len(top_10)), top_10['composite'], color=colors)\n",
    "axes[1, 1].set_title('Top 10 Words by Composite Score')\n",
    "axes[1, 1].set_xlabel('Rank')\n",
    "axes[1, 1].set_ylabel('Composite Score')\n",
    "axes[1, 1].set_xticks(range(len(top_10)))\n",
    "axes[1, 1].set_xticklabels(top_10['word'], rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a91b5d",
   "metadata": {},
   "source": [
    "## Strategy Recommendation\n",
    "\n",
    "Let's see how to get strategic recommendations for the next word to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendation from \"color\"\n",
    "current_word = \"color\"\n",
    "lambdas = (0.35, 0.2, 0.25, 0.1, 0.1)  # Default weights\n",
    "\n",
    "try:\n",
    "    recommendation = recommend_next(current_word, graph, TRAP_LETTERS, pagerank, lambdas)\n",
    "    \n",
    "    print(f\"Starting from: {current_word}\")\n",
    "    print(f\"Best recommendation: {recommendation['best']['word']}\")\n",
    "    print(f\"Best score: {recommendation['best']['composite']:.3f}\")\n",
    "    \n",
    "    print(\"\\nTop 5 candidates:\")\n",
    "    for i, candidate in enumerate(recommendation['candidates'][:5]):\n",
    "        print(f\"{i+1}. {candidate['word']} (score: {candidate['composite']:.3f})\")\n",
    "        \n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81c54c",
   "metadata": {},
   "source": [
    "## Exploring Different Starting Points\n",
    "\n",
    "Let's analyze how recommendations change from different starting words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc42818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple starting words\n",
    "test_words = ['start', 'animal', 'blue', 'rock']\n",
    "recommendations = {}\n",
    "\n",
    "for word in test_words:\n",
    "    if word in graph:\n",
    "        try:\n",
    "            rec = recommend_next(word, graph, TRAP_LETTERS, pagerank, lambdas)\n",
    "            recommendations[word] = rec['best']\n",
    "        except ValueError:\n",
    "            recommendations[word] = None\n",
    "\n",
    "print(\"Recommendations from different starting words:\")\n",
    "for start_word, best_rec in recommendations.items():\n",
    "    if best_rec:\n",
    "        print(f\"{start_word} -> {best_rec['word']} (score: {best_rec['composite']:.3f})\")\n",
    "    else:\n",
    "        print(f\"{start_word} -> No valid recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69040fc7",
   "metadata": {},
   "source": [
    "## Parameter Sensitivity Analysis\n",
    "\n",
    "Let's see how changing the scoring parameters affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different PageRank alpha values\n",
    "alpha_values = [1.0, 1.5, 2.0, 3.0]\n",
    "alpha_results = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    pr = biased_pagerank(graph, TRAP_LETTERS, alpha=alpha)\n",
    "    \n",
    "    # Compute average scores for trap vs non-trap words\n",
    "    trap_scores = [composite(word, graph, TRAP_LETTERS, pr) \n",
    "                   for word in graph if word and word[0] in TRAP_LETTERS]\n",
    "    non_trap_scores = [composite(word, graph, TRAP_LETTERS, pr) \n",
    "                       for word in graph if not (word and word[0] in TRAP_LETTERS)]\n",
    "    \n",
    "    alpha_results.append({\n",
    "        'alpha': alpha,\n",
    "        'trap_mean': np.mean(trap_scores),\n",
    "        'non_trap_mean': np.mean(non_trap_scores),\n",
    "        'separation': np.mean(trap_scores) - np.mean(non_trap_scores)\n",
    "    })\n",
    "\n",
    "alpha_df = pd.DataFrame(alpha_results)\n",
    "print(\"Effect of PageRank alpha parameter:\")\n",
    "print(alpha_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot alpha sensitivity\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(alpha_df['alpha'], alpha_df['trap_mean'], 'ro-', label='Trap words')\n",
    "plt.plot(alpha_df['alpha'], alpha_df['non_trap_mean'], 'bo-', label='Non-trap words')\n",
    "plt.xlabel('Alpha Parameter')\n",
    "plt.ylabel('Mean Composite Score')\n",
    "plt.title('Score by Alpha Parameter')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(alpha_df['alpha'], alpha_df['separation'], 'go-')\n",
    "plt.xlabel('Alpha Parameter')\n",
    "plt.ylabel('Score Separation')\n",
    "plt.title('Trap vs Non-Trap Separation')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdba080",
   "metadata": {},
   "source": [
    "## Individual Word Analysis\n",
    "\n",
    "Let's do a detailed analysis of a specific word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a specific word in detail\n",
    "word_to_analyze = \"start\"\n",
    "\n",
    "if word_to_analyze in graph:\n",
    "    print(f\"Detailed Analysis of '{word_to_analyze}':\")\n",
    "    print(f\"One-step RST probability: {one_step_rst_prob(word_to_analyze, graph, TRAP_LETTERS):.3f}\")\n",
    "    print(f\"Escape hardness: {escape_hardness(word_to_analyze, graph, TRAP_LETTERS):.3f}\")\n",
    "    print(f\"PageRank score: {pagerank.get(word_to_analyze, 0.0):.6f}\")\n",
    "    print(f\"2-step RST probability: {k_step_rst_prob(word_to_analyze, graph, TRAP_LETTERS, k=2):.3f}\")\n",
    "    print(f\"Minimax score: {minimax_topm(word_to_analyze, graph, TRAP_LETTERS):.3f}\")\n",
    "    print(f\"Composite score: {composite(word_to_analyze, graph, TRAP_LETTERS, pagerank):.3f}\")\n",
    "    \n",
    "    print(f\"\\nOutgoing connections from '{word_to_analyze}':\")\n",
    "    connections = graph[word_to_analyze]\n",
    "    sorted_connections = sorted(connections.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for target, weight in sorted_connections:\n",
    "        is_trap = target and target[0] in TRAP_LETTERS\n",
    "        trap_indicator = \"(TRAP)\" if is_trap else \"\"\n",
    "        print(f\"  -> {target}: {weight:.1f} {trap_indicator}\")\n",
    "else:\n",
    "    print(f\"Word '{word_to_analyze}' not found in graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a160808",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the basic usage of RST Trap Finder:\n",
    "\n",
    "1. **Data Loading**: How to load and explore word association graphs\n",
    "2. **Scoring**: Computing various trap effectiveness metrics\n",
    "3. **Analysis**: Comparing trap vs non-trap words\n",
    "4. **Strategy**: Getting recommendations for next moves\n",
    "5. **Parameter Tuning**: Understanding how parameters affect results\n",
    "\n",
    "### Key Insights from Sample Data:\n",
    "- Words starting with R/S/T don't automatically score highest (the composite metric considers multiple factors)\n",
    "- The PageRank bias parameter significantly affects trap/non-trap separation\n",
    "- Strategic recommendations depend on the specific graph structure and weights\n",
    "\n",
    "### Next Steps:\n",
    "- Explore the advanced analysis notebook for machine learning features\n",
    "- Try the visualization notebook for interactive plots\n",
    "- Use your own word association data to find domain-specific trap words\n",
    "\n",
    "For more advanced features, see:\n",
    "- `advanced_analysis.ipynb`: ML models and parameter optimization\n",
    "- `visualization_guide.ipynb`: Interactive visualizations\n",
    "- `performance_optimization.ipynb`: Large-scale processing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
